---
sidebar_position: 7
title: タブの中に、タブの入れ子の例
---

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

ソースによると、LangChainで提供されている様々なチャットモデルをインスタンス化するコードは、使用するモデルによって異なります。
以下は、ソースで示されている各チャットモデルのインスタンス化コードとその解説です。

<Tabs>
  <TabItem value="OpenAI" label="OpenAI" default>
    <Tabs>
      <TabItem value="npm" label="npm" default>
        ```bash
        npm i langchain
        ```
      </TabItem>
      <TabItem value="yarn" label="yarn">
        ```bash
        yarn add langchain
        ```
      </TabItem>
      <TabItem value="pnpm" label="pnpm">
        ```bash
        pnpm add langchain
        ```
      </TabItem>
    </Tabs>
    ```js
    import { ChatOpenAI } from "@langchain/openai";
    const model = new ChatOpenAI({ model: "gpt-4" });
    ```

    - 最初に`@langchain/openai`から`ChatOpenAI`をインポートします。
    - `new ChatOpenAI()` で`ChatOpenAI`クラスのインスタンスを作成します。
    - この例では、`model`パラメータで"gpt-4"を指定することで、GPT-4モデルを使用することを明示しています。

  </TabItem>
  <TabItem value="Anthropic" label="Anthropic">
    ```js
    import { ChatAnthropic } from "@langchain/anthropic";
    const model = new ChatAnthropic({
      model: "claude-3-5-sonnet-20240620",
      temperature: 0
    });
    ```

    - `@langchain/anthropic`から`ChatAnthropic`をインポートします。
    - `new ChatAnthropic()`で`ChatAnthropic`クラスのインスタンスを作成します。
    - `model`パラメータで使用するAnthropicのモデルを指定します。
    - `temperature`パラメータで応答のランダム性を制御します。0は最も確定的で、値が大きいほどランダムになります。 
  
  </TabItem>
  <TabItem value="FireworksAI" label="FireworksAI">
    ```js
    import { ChatFireworks } from "@langchain/community/chat_models/fireworks";
    const model = new ChatFireworks({
      model: "accounts/fireworks/models/llama-v3p1-70b-instruct",
      temperature: 0
    });
    ```

    - `@langchain/community/chat_models/fireworks`から`ChatFireworks`をインポートします。 
    - `new ChatFireworks()`で`ChatFireworks`クラスのインスタンスを作成します。
    - `model`パラメータで使用するFireworksAIのモデルを指定します。
    - `temperature`パラメータで応答のランダム性を制御します。

  </TabItem>
  <TabItem value="MistralAI" label="MistralAI">
    ```js
    import { ChatMistralAI } from "@langchain/mistralai";
    const model = new ChatMistralAI({
      model: "mistral-large-latest",
      temperature: 0
    });
    ```

    -  `@langchain/mistralai`から`ChatMistralAI`をインポートします。
    - `new ChatMistralAI()`で`ChatMistralAI`クラスのインスタンスを作成します。
    - `model`パラメータで使用するMistralAIのモデルを指定します。
    - `temperature`パラメータで応答のランダム性を制御します。

  </TabItem>
  <TabItem value="Groq" label="Groq">
    ```js
    import { ChatGroq } from "@langchain/groq";
    const model = new ChatGroq({
      model: "mixtral-8x7b-32768",
      temperature: 0
    });
    
    ```
    - `@langchain/groq`から`ChatGroq`をインポートします。
    - `new ChatGroq()`で`ChatGroq`クラスのインスタンスを作成します。
    - `model`パラメータで使用するGroqのモデルを指定します。
    - `temperature`パラメータで応答のランダム性を制御します。

  </TabItem>
  <TabItem value="VertexAI" label="VertexAI">
    ```js
    import { ChatVertexAI } from "@langchain/google-vertexai";
    const model = new ChatVertexAI({
      model: "gemini-1.5-flash",
      temperature: 0
    });
    ```
    - `@langchain/google-vertexai`から`ChatVertexAI`をインポートします。
    - `new ChatVertexAI()`で`ChatVertexAI`クラスのインスタンスを作成します。
    - `model`パラメータで使用するVertexAIのモデルを指定します。
    - `temperature`パラメータで応答のランダム性を制御します。

  </TabItem>
</Tabs>
